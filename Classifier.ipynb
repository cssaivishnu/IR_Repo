{"cells":[{"cell_type":"markdown","source":["Clone the github repo"],"metadata":{"id":"y0skI-nk54UH"}},{"cell_type":"code","source":["!git clone --branch scratch https://github.com/cssaivishnu/IR_Repo.git"],"metadata":{"id":"nVLI5KUx2HL5","outputId":"6476c97b-ec5e-456c-ebf8-f8bece2ec971","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681284971779,"user_tz":-330,"elapsed":152488,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'IR_Repo'...\n","remote: Enumerating objects: 63757, done.\u001b[K\n","remote: Counting objects: 100% (70/70), done.\u001b[K\n","remote: Compressing objects: 100% (70/70), done.\u001b[K\n","remote: Total 63757 (delta 36), reused 0 (delta 0), pack-reused 63687\u001b[K\n","Receiving objects: 100% (63757/63757), 2.34 GiB | 17.95 MiB/s, done.\n","Resolving deltas: 100% (55/55), done.\n","Updating files: 100% (63289/63289), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"O9e4eRhtB52N"},"source":["Import the essential libraries"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"gkxVB3cmG3lM","executionInfo":{"status":"ok","timestamp":1681289893685,"user_tz":-330,"elapsed":1070,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import shutil\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import json\n","import random\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import pandas as pd\n","\n","tf.random.set_seed(20)\n","random.seed = 20\n","np.random.seed = 20"]},{"cell_type":"markdown","metadata":{"id":"EqF-6BAL4387"},"source":["Make the main repo as the current active repository"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c62b65f-d6bd-4ff8-b38c-eb411b9c1b0a","id":"qqKEWeFM4387","executionInfo":{"status":"ok","timestamp":1681285259579,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/IR_Repo\n"]}],"source":["os.chdir('/content/IR_Repo')\n","cwd = os.getcwd()\n","print(cwd)"]},{"cell_type":"markdown","metadata":{"id":"d3vWKcjbY9R9"},"source":["From the complete dataset of approximately 63285 images from 35 categories, we consider only the product categories with atleast 150 images."]},{"cell_type":"code","source":["def func(name):\n","    for i in range(len(name)):\n","        if name[i] == '&' or name[i] == '-':\n","            name = name[:i] + '_' + name[i+1:]\n","    return name"],"metadata":{"id":"8txyzYs7Yyj4","executionInfo":{"status":"ok","timestamp":1681285265395,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"cOoxFhBQN1w2","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"b67a62c7-a0dc-48bf-f658-8476173aa1fe","executionInfo":{"status":"error","timestamp":1681285413309,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-0bec81f181e0>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimages_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'dataset'"]}],"source":["dir_path = 'atlas_dataset_full'\n","dir_count = 0\n","active_dir_count = 0\n","complete_dir_count = 0\n","total_images = 0\n","images_list = []\n","\n","os.mkdir('dataset')\n","\n","for name in sorted(os.listdir(dir_path)):\n","    if os.path.isdir(os.path.join(dir_path, name)):\n","        path = os.path.join(dir_path, name)\n","        path = os.path.join(path, 'images')\n","        num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n","        if(num_files > 150):\n","            active_dir_count = active_dir_count + 1\n","            name = func(name)\n","            new_path = os.path.join('dataset', name)\n","            os.mkdir(new_path)\n","            i = 0\n","            for f in os.listdir(path):\n","                if i == 600:\n","                    complete_dir_count = complete_dir_count + 1\n","                    break\n","                if os.path.isfile(os.path.join(path, f)):\n","                    i = i + 1\n","                    src = os.path.join(path, f)\n","                    fname = '{:03d}'.format(i) + '.' + f.split('.')[-1]\n","                    dst = os.path.join(new_path, fname)\n","                    shutil.copy2(src, dst)\n","            images_list.append(i)\n","        total_images = total_images + num_files\n","        dir_count += 1\n","\n","print(\"Total Number of categories:\", dir_count)\n","print(\"Number of categories with atleast 150 images:\", active_dir_count)\n","print(\"Number of categories with 600 images:\", complete_dir_count)\n","print(\"Total Number of Images:\", total_images)"]},{"cell_type":"markdown","source":["We find that 22 out of these 35 categories only have atleast 150 images\n","\n","We want to have 600 images from each of the 22 product categories, out of which 4 of them have less than 600 images.\n","\n","Now, we will perform image augmentation to increase the number of images in those 4 product categories with less than 600 images to 600 images"],"metadata":{"id":"p9-2Y9LG_df2"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"a2b_YKONJFek","executionInfo":{"status":"ok","timestamp":1681285449564,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["# Here, the image is flipped horizontally to create a new image\n","\n","def horizontalflipping_augmentation(path, new_path):\n","    # Define the horizontal flipping transformation\n","    transform = transforms.Compose([\n","        transforms.RandomHorizontalFlip(p=1),\n","    ])\n","\n","    # Load the image\n","    img = Image.open(path)\n","\n","    # Apply the horizontal flipping transformation\n","    img_flipped = transform(img)\n","\n","    # Display the original and flipped images\n","    # img.show()\n","    # img_flipped.show()\n","\n","    # Save the horizontally flipped image\n","    img.save(new_path)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"bISEXc2PFUaY","executionInfo":{"status":"ok","timestamp":1681285449565,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["# Here, the image is modified by varying color glittering entities like contrast, brightness etc.\n","\n","def colorgittering_augmentation(path,new_path):\n","    # Load the image\n","    img = cv2.imread(path)\n","\n","    # Define the range of color jittering values\n","    brightness = 0.1\n","    contrast = 0.1\n","    saturation = 0.1\n","    hue = 0.1\n","\n","    # Convert the image from BGR to HSV color space\n","    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","\n","    # Apply color jittering to the image\n","    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * (1 + brightness), 0, 255)\n","    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * (1 + contrast), 0, 255)\n","    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * (1 + saturation), 0, 255)\n","    img_hsv[:, :, 0] = np.clip(img_hsv[:, :, 0] * (1 + hue), 0, 255)\n","\n","    # Convert the image back to BGR color space\n","    img_jittered = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n","\n","    # Display the original and jittered images\n","    # cv2_imshow(img)\n","    # cv2_imshow(img_jittered)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","\n","    # Save the color gritted image\n","    cv2.imwrite(new_path, img)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"XcdGedzTOWDM","executionInfo":{"status":"ok","timestamp":1681285450669,"user_tz":-330,"elapsed":1,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["# Here, the image is randomly scaled to a feasible size\n","\n","def randomscaling_augmentation(path,new_path):\n","    # Load the image\n","    img = Image.open(path)\n","    width, height = img.size\n","    size = int(min(width,height)*0.9)\n","\n","    # Define the random scaling transformation\n","    transform = transforms.Compose([\n","        transforms.RandomResizedCrop(size=size, scale=(0.8, 1.0)),\n","    ])\n","\n","    # Apply the random scaling transformation\n","    img_scaled = transform(img)\n","\n","    # Display the original and scaled images\n","    # img.show()\n","    # img_scaled.show()\n","\n","    # Save the randomly scaled image\n","    img.save(new_path)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"8EZYZlEw-zm3","executionInfo":{"status":"ok","timestamp":1681285475260,"user_tz":-330,"elapsed":1244,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["dir_path = 'dataset'\n","images_list = []\n","name_list = sorted(os.listdir(dir_path))\n","\n","for name in name_list:\n","    if os.path.isdir(os.path.join(dir_path, name)):\n","        path = os.path.join(dir_path, name)\n","        num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n","        images_list.append(num_files)\n","        if num_files != 600:\n","            # print(num_files)\n","            # print(name)\n","            for f in os.listdir(path):\n","                if os.path.isfile(os.path.join(path, f)):\n","                    img_name = int(f.split('.')[0])\n","                    for i in range(1,4):\n","                        new_img_name = img_name + num_files*i\n","                        if new_img_name > 600:\n","                            break\n","                        new_img_name = '{:03d}'.format(new_img_name) + '.' + f.split('.')[-1]\n","                        img_path = os.path.join(path,f)\n","                        new_img_path = os.path.join(path,new_img_name)\n","                        if i == 1:\n","                            horizontalflipping_augmentation(img_path,new_img_path)\n","                        if i == 2:\n","                            colorgittering_augmentation(img_path,new_img_path)\n","                        if i == 3:\n","                            randomscaling_augmentation(img_path,new_img_path)"]},{"cell_type":"markdown","metadata":{"id":"1dBb7kdLvGf1"},"source":["Create the label encodings mapping the product categories"]},{"cell_type":"code","source":["dir_path = 'dataset'\n","i = 0\n","name_to_label = dict()\n","label_to_name = dict()\n","\n","for name in name_list:\n","    if os.path.isdir(os.path.join(dir_path, name)):\n","        name_to_label[name] = i\n","        label_to_name[i] = name\n","        i = i + 1"],"metadata":{"id":"eDllHTjgUGMJ","executionInfo":{"status":"ok","timestamp":1681285482302,"user_tz":-330,"elapsed":633,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OA_aLZBZwCRs"},"source":["Load 500 out of 600 images from each product category and modify them to (56, 56) shape for training and evaluation of the model"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"MdWasMiGBIoY","executionInfo":{"status":"ok","timestamp":1681285631419,"user_tz":-330,"elapsed":112078,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"outputs":[],"source":["dir_path = 'dataset'\n","dataset = []\n","image_shape = (56, 56)\n","\n","for name in name_list:\n","    if os.path.isdir(os.path.join(dir_path, name)):\n","        path = os.path.join(dir_path, name)\n","        # print(name_to_label[name])\n","        for f in os.listdir(path):\n","            if os.path.isfile(os.path.join(path, f)):\n","                num = int(f.split('.')[0])\n","                if num > 500:\n","                    continue\n","                img_path = os.path.join(path, f)\n","                img = Image.open(img_path)\n","                img = img.resize(image_shape, Image.ANTIALIAS)\n","                pixels = img.load()\n","                lst = []\n","                for i in range(img.size[0]):\n","                    lst1 = []\n","                    for j in range(img.size[1]):\n","                        lst1.append(list(pixels[i, j]))\n","                    lst.append(lst1)\n","                lst = np.array(lst)\n","                tupl = (lst,name_to_label[name])\n","                dataset.append(tupl)"]},{"cell_type":"markdown","source":["Shuffle the dataset for randomness and split the dataset into features(X) and labels(y)"],"metadata":{"id":"RHqNOE3pIMTD"}},{"cell_type":"code","source":["random.shuffle(dataset)\n","X = []\n","y = []\n","\n","for tupl in dataset:\n","    x, yy = tupl\n","    X.append(x)\n","    y.append(yy)\n","X = np.array(X)\n","y = np.array(y).reshape(11000,1)\n","\n","# Just clear the space\n","# dataset = []"],"metadata":{"id":"ebBGsaQz4YBr","executionInfo":{"status":"ok","timestamp":1681285631420,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-n4yzA_cGjk","executionInfo":{"status":"ok","timestamp":1681285744547,"user_tz":-330,"elapsed":603,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}},"outputId":"d2d26eb5-3bd8-48b1-d5d0-b677472e4101"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 6],\n","       [ 5],\n","       [20],\n","       ...,\n","       [15],\n","       [ 7],\n","       [14]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"ank6_wq74388"},"source":["Initialisation"]},{"cell_type":"code","source":["input_shape = (56, 56, 3)\n","num_categories = len(name_list)"],"metadata":{"id":"C51FYTJiNkgt","executionInfo":{"status":"ok","timestamp":1681285800742,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["Split the dataset into train and test data"],"metadata":{"id":"NRS1mudkPFuk"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","print('X_train:', X_train.shape)\n","print('X_test:', X_test.shape)\n","print('y_train:', y_train.shape)\n","print('y_test:', y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyQrQMexPKFy","outputId":"85b303fd-bd3f-4d22-f67e-fb0c3bb95b21","executionInfo":{"status":"ok","timestamp":1681290007882,"user_tz":-330,"elapsed":5569,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: (8800, 56, 56, 3)\n","X_test: (2200, 56, 56, 3)\n","y_train: (8800, 1)\n","y_test: (2200, 1)\n"]}]},{"cell_type":"markdown","source":["Image Data Augmentation"],"metadata":{"id":"mJhF1icQPgqN"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.RandomFlip('horizontal'),\n","        layers.RandomRotation(0.02),\n","        layers.RandomWidth(0.2),\n","        layers.RandomHeight(0.2)\n","    ]\n",")\n","\n","data_augmentation.layers[0].adapt(X_train)"],"metadata":{"id":"UMt-JY3iLtq2","executionInfo":{"status":"ok","timestamp":1681285855774,"user_tz":-330,"elapsed":10968,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["Define the Supervised Contrastive Loss Function that will be used in training the model "],"metadata":{"id":"xsxbj2dvRFXV"}},{"cell_type":"code","source":["class SupervisedContrastiveLoss(keras.losses.Loss):\n","    def __init__(self, temperature=1, name=None):\n","        super(SupervisedContrastiveLoss, self).__init__(name=name)\n","        self.temperature = temperature\n","    def __call__(self, labels, feature_vectors, sample_weight=None):\n","        # normalize the feature vectors\n","        feature_vectors_normailzed = tf.math.l2_normalize(feature_vectors, axis=1)\n","        # Compute Logits\n","        logits = tf.divide(\n","            tf.matmul(\n","                feature_vectors_normailzed, tf.transpose(feature_vectors_normailzed)\n","            ),\n","            self.temperature,\n","        )\n","        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"],"metadata":{"id":"rR3Y2t3wS4pQ","executionInfo":{"status":"ok","timestamp":1681285855774,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["Create an encoder to encode the images pixel data using the RNN - ResNet50V2"],"metadata":{"id":"j0ES_vSeYNZY"}},{"cell_type":"code","source":["def create_encoder():\n","    resnet = keras.applications.ResNet50V2(\n","        include_top=False, weights=None, input_shape=input_shape, pooling='avg'\n","    )\n","    inputs = keras.Input(shape=input_shape)\n","    augmented = data_augmentation(inputs)\n","    outputs = resnet(augmented)\n","    model = keras.Model(inputs=inputs, outputs=outputs, name='encoder')\n","    return model"],"metadata":{"id":"vfqUfbAOXeOK","executionInfo":{"status":"ok","timestamp":1681285855775,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["Adding a Projection head"],"metadata":{"id":"XSpCGwfQdAEa"}},{"cell_type":"code","source":["def add_projection_head(encoder, projection_units):\n","    inputs = keras.Input(shape=input_shape)\n","    features = encoder(inputs)\n","    outputs = layers.Dense(projection_units, activation='relu')(features)\n","    model = keras.Model(\n","        inputs=inputs, outputs=outputs, name='encoder_with_projection_head'\n","    )\n","    return model"],"metadata":{"id":"QkKIGzMEaehd","executionInfo":{"status":"ok","timestamp":1681285856407,"user_tz":-330,"elapsed":1,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["Train the encoder with Supervised Contrastive Loss defined above for better encoding"],"metadata":{"id":"Hrr30sSHfMig"}},{"cell_type":"code","source":["learning_rate = 0.001\n","batch_size = 100\n","projection_units = 256\n","epochs = 50\n","temperature = 0.05\n","\n","encoder = create_encoder()\n","encoder.summary()\n","encoder_with_projection_head = add_projection_head(encoder, projection_units)\n","encoder_with_projection_head.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate),\n","    loss=SupervisedContrastiveLoss(temperature)\n",")\n","encoder_with_projection_head.summary()\n","\n","with tf.device('/gpu:0'):\n","    history = encoder_with_projection_head.fit(\n","        x=X_train, y=y_train, batch_size=batch_size, epochs=epochs\n","    )"],"metadata":{"id":"lEwNpfm5d2nd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94143afe-b530-45f2-afe2-8874b10affe1","executionInfo":{"status":"ok","timestamp":1681286462658,"user_tz":-330,"elapsed":591779,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 56, 56, 3)]       0         \n","                                                                 \n"," sequential (Sequential)     (None, None, None, 3)     7         \n","                                                                 \n"," resnet50v2 (Functional)     (None, 2048)              23564800  \n","                                                                 \n","=================================================================\n","Total params: 23,564,807\n","Trainable params: 23,519,360\n","Non-trainable params: 45,447\n","_________________________________________________________________\n","Model: \"encoder_with_projection_head\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 56, 56, 3)]       0         \n","                                                                 \n"," encoder (Functional)        (None, 2048)              23564807  \n","                                                                 \n"," dense (Dense)               (None, 256)               524544    \n","                                                                 \n","=================================================================\n","Total params: 24,089,351\n","Trainable params: 24,043,904\n","Non-trainable params: 45,447\n","_________________________________________________________________\n","Epoch 1/50\n","88/88 [==============================] - 90s 467ms/step - loss: 4.1535\n","Epoch 2/50\n","88/88 [==============================] - 19s 216ms/step - loss: 3.7092\n","Epoch 3/50\n","88/88 [==============================] - 13s 153ms/step - loss: 3.4920\n","Epoch 4/50\n","88/88 [==============================] - 13s 146ms/step - loss: 3.3318\n","Epoch 5/50\n","88/88 [==============================] - 13s 144ms/step - loss: 3.2345\n","Epoch 6/50\n","88/88 [==============================] - 12s 138ms/step - loss: 3.1665\n","Epoch 7/50\n","88/88 [==============================] - 11s 127ms/step - loss: 3.1250\n","Epoch 8/50\n","88/88 [==============================] - 11s 128ms/step - loss: 3.0434\n","Epoch 9/50\n","88/88 [==============================] - 10s 117ms/step - loss: 2.9833\n","Epoch 10/50\n","88/88 [==============================] - 10s 118ms/step - loss: 2.9388\n","Epoch 11/50\n","88/88 [==============================] - 11s 127ms/step - loss: 2.9336\n","Epoch 12/50\n","88/88 [==============================] - 10s 119ms/step - loss: 2.8674\n","Epoch 13/50\n","88/88 [==============================] - 10s 117ms/step - loss: 2.8206\n","Epoch 14/50\n","88/88 [==============================] - 10s 110ms/step - loss: 2.8172\n","Epoch 15/50\n","88/88 [==============================] - 10s 114ms/step - loss: 2.7730\n","Epoch 16/50\n","88/88 [==============================] - 10s 112ms/step - loss: 2.7467\n","Epoch 17/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.6963\n","Epoch 18/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.6905\n","Epoch 19/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.6795\n","Epoch 20/50\n","88/88 [==============================] - 10s 108ms/step - loss: 2.6501\n","Epoch 21/50\n","88/88 [==============================] - 10s 110ms/step - loss: 2.6338\n","Epoch 22/50\n","88/88 [==============================] - 9s 107ms/step - loss: 2.6351\n","Epoch 23/50\n","88/88 [==============================] - 10s 114ms/step - loss: 2.6138\n","Epoch 24/50\n","88/88 [==============================] - 10s 109ms/step - loss: 2.5779\n","Epoch 25/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.5469\n","Epoch 26/50\n","88/88 [==============================] - 10s 108ms/step - loss: 2.5597\n","Epoch 27/50\n","88/88 [==============================] - 10s 110ms/step - loss: 2.5253\n","Epoch 28/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.5038\n","Epoch 29/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.4968\n","Epoch 30/50\n","88/88 [==============================] - 10s 109ms/step - loss: 2.4737\n","Epoch 31/50\n","88/88 [==============================] - 10s 112ms/step - loss: 2.4830\n","Epoch 32/50\n","88/88 [==============================] - 9s 105ms/step - loss: 2.4508\n","Epoch 33/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.4608\n","Epoch 34/50\n","88/88 [==============================] - 10s 109ms/step - loss: 2.4242\n","Epoch 35/50\n","88/88 [==============================] - 9s 107ms/step - loss: 2.4281\n","Epoch 36/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.4152\n","Epoch 37/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.3942\n","Epoch 38/50\n","88/88 [==============================] - 9s 105ms/step - loss: 2.4043\n","Epoch 39/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.3671\n","Epoch 40/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.3850\n","Epoch 41/50\n","88/88 [==============================] - 10s 112ms/step - loss: 2.3369\n","Epoch 42/50\n","88/88 [==============================] - 10s 109ms/step - loss: 2.3471\n","Epoch 43/50\n","88/88 [==============================] - 9s 105ms/step - loss: 2.3244\n","Epoch 44/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.3421\n","Epoch 45/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.3243\n","Epoch 46/50\n","88/88 [==============================] - 9s 105ms/step - loss: 2.2998\n","Epoch 47/50\n","88/88 [==============================] - 9s 108ms/step - loss: 2.2991\n","Epoch 48/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.2703\n","Epoch 49/50\n","88/88 [==============================] - 9s 106ms/step - loss: 2.2944\n","Epoch 50/50\n","88/88 [==============================] - 10s 108ms/step - loss: 2.2511\n"]}]},{"cell_type":"markdown","source":["Creating and training the classifier using the pretrained encoder, and saving the model into a .h5 file"],"metadata":{"id":"hEU6SyBaBwj3"}},{"cell_type":"code","source":["def create_classifier(encoder, dropout_rate, hidden_units, learning_rate, trainable=True):\n","    for layer in encoder.layers:\n","        layer.trainable = trainable\n","    inputs = keras.Input(shape=input_shape)\n","    features = encoder(inputs)\n","    features = layers.Dropout(dropout_rate)(features)\n","    features = layers.Dense(hidden_units, activation='relu')(features)\n","    features = layers.Dropout(dropout_rate)(features)\n","    outputs = layers.Dense(num_categories, activation='softmax')(features)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs, name = 'classifier')\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate),\n","        loss=keras.losses.SparseCategoricalCrossentropy(),\n","        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    )\n","    return model"],"metadata":{"id":"FERzd63ofL12","executionInfo":{"status":"ok","timestamp":1681286462659,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["dropout_rate = 0.5\n","hidden_units = 512\n","learning_rate = 0.001\n","batch_size = 100\n","epochs = 100\n","\n","classifier = create_classifier(encoder, dropout_rate, hidden_units, learning_rate, trainable=False)\n","classifier.summary()\n","with tf.device('/gpu:0'):\n","    history = classifier.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","classifier.save('classifier.h5')"],"metadata":{"id":"C_Mq2HYPN5uo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6787c80c-9d8a-4b42-ef4a-132d742a8e87","executionInfo":{"status":"ok","timestamp":1681286782280,"user_tz":-330,"elapsed":317446,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"classifier\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 56, 56, 3)]       0         \n","                                                                 \n"," encoder (Functional)        (None, 2048)              23564807  \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               1049088   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 22)                11286     \n","                                                                 \n","=================================================================\n","Total params: 24,625,181\n","Trainable params: 1,060,374\n","Non-trainable params: 23,564,807\n","_________________________________________________________________\n","Epoch 1/100\n","71/71 [==============================] - 10s 80ms/step - loss: 0.9870 - sparse_categorical_accuracy: 0.7033 - val_loss: 0.6035 - val_sparse_categorical_accuracy: 0.7807\n","Epoch 2/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.7094 - sparse_categorical_accuracy: 0.7631 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7881\n","Epoch 3/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.7818 - val_loss: 0.5398 - val_sparse_categorical_accuracy: 0.8085\n","Epoch 4/100\n","71/71 [==============================] - 4s 50ms/step - loss: 0.6264 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.5121 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 5/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.6077 - sparse_categorical_accuracy: 0.7898 - val_loss: 0.5335 - val_sparse_categorical_accuracy: 0.8057\n","Epoch 6/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5997 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.5394 - val_sparse_categorical_accuracy: 0.8062\n","Epoch 7/100\n","71/71 [==============================] - 3s 48ms/step - loss: 0.5782 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.8091\n","Epoch 8/100\n","71/71 [==============================] - 4s 50ms/step - loss: 0.5829 - sparse_categorical_accuracy: 0.7878 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.8091\n","Epoch 9/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5641 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.5081 - val_sparse_categorical_accuracy: 0.8148\n","Epoch 10/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.5149 - val_sparse_categorical_accuracy: 0.8153\n","Epoch 11/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.7932 - val_loss: 0.4945 - val_sparse_categorical_accuracy: 0.8119\n","Epoch 12/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5403 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.5048 - val_sparse_categorical_accuracy: 0.8188\n","Epoch 13/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7884 - val_loss: 0.4999 - val_sparse_categorical_accuracy: 0.8165\n","Epoch 14/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.4965 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 15/100\n","71/71 [==============================] - 3s 47ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.5101 - val_sparse_categorical_accuracy: 0.8170\n","Epoch 16/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.8222\n","Epoch 17/100\n","71/71 [==============================] - 3s 49ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.5000 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 18/100\n","71/71 [==============================] - 3s 49ms/step - loss: 0.5427 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4997 - val_sparse_categorical_accuracy: 0.8080\n","Epoch 19/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.5120 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 20/100\n","71/71 [==============================] - 3s 47ms/step - loss: 0.5292 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4942 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 21/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5212 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8239\n","Epoch 22/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.4963 - val_sparse_categorical_accuracy: 0.8182\n","Epoch 23/100\n","71/71 [==============================] - 3s 46ms/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7997 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.8182\n","Epoch 24/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5299 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.4915 - val_sparse_categorical_accuracy: 0.8188\n","Epoch 25/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.8023 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.8205\n","Epoch 26/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5262 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.8233\n","Epoch 27/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5156 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 0.8233\n","Epoch 28/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5239 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.4918 - val_sparse_categorical_accuracy: 0.8182\n","Epoch 29/100\n","71/71 [==============================] - 3s 46ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4870 - val_sparse_categorical_accuracy: 0.8205\n","Epoch 30/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5220 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4914 - val_sparse_categorical_accuracy: 0.8170\n","Epoch 31/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5259 - sparse_categorical_accuracy: 0.8007 - val_loss: 0.4910 - val_sparse_categorical_accuracy: 0.8102\n","Epoch 32/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5338 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.4996 - val_sparse_categorical_accuracy: 0.8142\n","Epoch 33/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5179 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.8227\n","Epoch 34/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8170\n","Epoch 35/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4795 - val_sparse_categorical_accuracy: 0.8176\n","Epoch 36/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.8239\n","Epoch 37/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5125 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.4810 - val_sparse_categorical_accuracy: 0.8205\n","Epoch 38/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.5294 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.4931 - val_sparse_categorical_accuracy: 0.8148\n","Epoch 39/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5237 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.8244\n","Epoch 40/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4727 - val_sparse_categorical_accuracy: 0.8199\n","Epoch 41/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5306 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.8250\n","Epoch 42/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.4980 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 43/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5191 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.4862 - val_sparse_categorical_accuracy: 0.8244\n","Epoch 44/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5055 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.4834 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 45/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4850 - val_sparse_categorical_accuracy: 0.8119\n","Epoch 46/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5147 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.8176\n","Epoch 47/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5030 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.4995 - val_sparse_categorical_accuracy: 0.8136\n","Epoch 48/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5085 - sparse_categorical_accuracy: 0.8169 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8239\n","Epoch 49/100\n","71/71 [==============================] - 3s 47ms/step - loss: 0.5210 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.8193\n","Epoch 50/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4973 - sparse_categorical_accuracy: 0.8180 - val_loss: 0.5061 - val_sparse_categorical_accuracy: 0.8142\n","Epoch 51/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.5078 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8199\n","Epoch 52/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5188 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.5008 - val_sparse_categorical_accuracy: 0.8159\n","Epoch 53/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5231 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.4880 - val_sparse_categorical_accuracy: 0.8136\n","Epoch 54/100\n","71/71 [==============================] - 3s 39ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 55/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5186 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.4886 - val_sparse_categorical_accuracy: 0.8142\n","Epoch 56/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.4928 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 57/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5169 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8176\n","Epoch 58/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4908 - sparse_categorical_accuracy: 0.8172 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.8199\n","Epoch 59/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5115 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4894 - val_sparse_categorical_accuracy: 0.8182\n","Epoch 60/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5132 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.4757 - val_sparse_categorical_accuracy: 0.8222\n","Epoch 61/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.4901 - val_sparse_categorical_accuracy: 0.8199\n","Epoch 62/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5097 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4740 - val_sparse_categorical_accuracy: 0.8205\n","Epoch 63/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5044 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.4757 - val_sparse_categorical_accuracy: 0.8335\n","Epoch 64/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.5030 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.4961 - val_sparse_categorical_accuracy: 0.8244\n","Epoch 65/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4782 - val_sparse_categorical_accuracy: 0.8205\n","Epoch 66/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5031 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.4888 - val_sparse_categorical_accuracy: 0.8114\n","Epoch 67/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.4996 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8193\n","Epoch 68/100\n","71/71 [==============================] - 3s 40ms/step - loss: 0.5196 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.4861 - val_sparse_categorical_accuracy: 0.8170\n","Epoch 69/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.4804 - val_sparse_categorical_accuracy: 0.8136\n","Epoch 70/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4918 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.5037 - val_sparse_categorical_accuracy: 0.8182\n","Epoch 71/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4923 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.8159\n","Epoch 72/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4817 - sparse_categorical_accuracy: 0.8172 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.8227\n","Epoch 73/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.4890 - val_sparse_categorical_accuracy: 0.8210\n","Epoch 74/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4978 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.8278\n","Epoch 75/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.4913 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.4867 - val_sparse_categorical_accuracy: 0.8148\n","Epoch 76/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4942 - sparse_categorical_accuracy: 0.8166 - val_loss: 0.4849 - val_sparse_categorical_accuracy: 0.8239\n","Epoch 77/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.4980 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.4810 - val_sparse_categorical_accuracy: 0.8222\n","Epoch 78/100\n","71/71 [==============================] - 3s 49ms/step - loss: 0.4986 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4786 - val_sparse_categorical_accuracy: 0.8142\n","Epoch 79/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.4956 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.4813 - val_sparse_categorical_accuracy: 0.8244\n","Epoch 80/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4956 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.4928 - val_sparse_categorical_accuracy: 0.8131\n","Epoch 81/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4948 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.4899 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 82/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.4906 - val_sparse_categorical_accuracy: 0.8210\n","Epoch 83/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8188\n","Epoch 84/100\n","71/71 [==============================] - 3s 46ms/step - loss: 0.5032 - sparse_categorical_accuracy: 0.8089 - val_loss: 0.4910 - val_sparse_categorical_accuracy: 0.8153\n","Epoch 85/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.4740 - val_sparse_categorical_accuracy: 0.8239\n","Epoch 86/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4833 - sparse_categorical_accuracy: 0.8166 - val_loss: 0.5010 - val_sparse_categorical_accuracy: 0.8148\n","Epoch 87/100\n","71/71 [==============================] - 3s 45ms/step - loss: 0.5144 - sparse_categorical_accuracy: 0.8038 - val_loss: 0.4866 - val_sparse_categorical_accuracy: 0.8222\n","Epoch 88/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4962 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.5015 - val_sparse_categorical_accuracy: 0.8188\n","Epoch 89/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.5005 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8210\n","Epoch 90/100\n","71/71 [==============================] - 3s 44ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.5013 - val_sparse_categorical_accuracy: 0.8165\n","Epoch 91/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4892 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.4690 - val_sparse_categorical_accuracy: 0.8256\n","Epoch 92/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.5002 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 93/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.8179 - val_loss: 0.4978 - val_sparse_categorical_accuracy: 0.8193\n","Epoch 94/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4815 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.4944 - val_sparse_categorical_accuracy: 0.8261\n","Epoch 95/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4902 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8193\n","Epoch 96/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4788 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.4962 - val_sparse_categorical_accuracy: 0.8290\n","Epoch 97/100\n","71/71 [==============================] - 3s 41ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.8188\n","Epoch 98/100\n","71/71 [==============================] - 3s 42ms/step - loss: 0.4903 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.4707 - val_sparse_categorical_accuracy: 0.8216\n","Epoch 99/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.8278\n","Epoch 100/100\n","71/71 [==============================] - 3s 43ms/step - loss: 0.4843 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.4754 - val_sparse_categorical_accuracy: 0.8267\n","69/69 [==============================] - 2s 22ms/step - loss: 0.9172 - sparse_categorical_accuracy: 0.7418\n"]}]},{"cell_type":"markdown","source":["Get the prediction probabilities"],"metadata":{"id":"jb9fUPc-AOKv"}},{"cell_type":"code","source":["y_pred = classifier.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj6y32Wdntv-","executionInfo":{"status":"ok","timestamp":1681290022295,"user_tz":-330,"elapsed":1652,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}},"outputId":"75a512c3-0082-4f1e-b7c3-05b69debe156"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["69/69 [==============================] - 1s 13ms/step\n"]}]},{"cell_type":"markdown","source":["Get all the statistical metrics"],"metadata":{"id":"fH9H_-IYAgBj"}},{"cell_type":"code","source":["y_test = y_test.reshape(2200)\n","y_p = []\n","for pred in y_pred:\n","    y_p.append(np.argmax(pred))\n","y_pred = np.array(y_p)\n","\n","cm = confusion_matrix(y_test, y_pred)\n","ac = accuracy_score(y_test, y_pred)\n","prec = precision_score(y_test, y_pred, average=None)\n","reca = recall_score(y_test, y_pred, average=None)\n","f1_s = f1_score(y_test, y_pred, average=None)"],"metadata":{"id":"JNdW-IzopZt2","executionInfo":{"status":"ok","timestamp":1681290023670,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}}},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":["Create two Pandas DataFrames to note down the results and save them as a single excel file \n"],"metadata":{"id":"Ji8fdUnHAmBi"}},{"cell_type":"code","source":["lst = [f'label_{i}' for i in range(22)]\n","cm_df = pd.DataFrame(cm, columns=lst)\n","cm_df.reset_index(inplace=True)\n","cm_df.rename(columns={'index':'Product_Category'}, inplace=True)\n","cm_df[\"Product_Category\"] = cm_df[\"Product_Category\"].astype(str)\n","cm_df[\"Product_Category\"] = cm_df[\"Product_Category\"].apply(lambda x:label_to_name[x])\n","cm_df.reset_index(inplace=True)\n","cm_df.rename(columns={'index':'Labels'}, inplace=True)\n","cm_df['Labels'] = cm_df['Labels'].apply(lambda x:f'label_{x}')\n","cm_df.to_csv('confusion_matrix.csv')"],"metadata":{"id":"C4r_qhqUqFId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_df = cm_df.iloc[:,1:2]\n","metrics_df['Precision'] = prec\n","metrics_df['Precision'] = metrics_df['Precision'].apply(lambda x: round(x, 3))\n","metrics_df['Recall'] = reca\n","metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: round(x, 3))\n","metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: \"{:.3f}\".format(x)).astype(float)\n","metrics_df['f1_score'] = f1_s\n","metrics_df['f1_score'] = metrics_df['f1_score'].apply(lambda x: round(x, 3))\n","mean = ['Average', metrics_df['Precision'].mean(), metrics_df['Recall'].mean(), metrics_df['f1_score'].mean()]\n","min = ['Minimum', metrics_df['Precision'].min(), metrics_df['Recall'].min(), metrics_df['f1_score'].min()]\n","max = ['Maximum', metrics_df['Precision'].max(), metrics_df['Recall'].max(), metrics_df['f1_score'].max()]\n","metrics_df.loc[len(metrics_df)] = mean\n","metrics_df.loc[len(metrics_df)] = min\n","metrics_df.loc[len(metrics_df)] = max\n","metrics_df.to_csv(\"metrics.csv\")"],"metadata":{"id":"txpsnDFZsLs-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["writer = pd.ExcelWriter('Results.xlsx')\n","\n","# Write each dataframe to a different sheet\n","metrics_df.to_excel(writer, sheet_name='Metrics', index=False)\n","cm_df.to_excel(writer, sheet_name='Confusion_Matrix', index=False)\n","\n","# Save the file\n","writer.save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9tiyjy01Nof","executionInfo":{"status":"ok","timestamp":1681293535607,"user_tz":-330,"elapsed":1625,"user":{"displayName":"Sai Vishnu C S","userId":"14557922241088095199"}},"outputId":"c62ec0b5-fcad-4ddd-df9d-8617d52e3f4d"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-118-ce1d72033f78>:8: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n","  writer.save()\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}