{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cssaivishnu/IR_Repo/blob/main/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9e4eRhtB52N"
      },
      "source": [
        "Import the essential libraries and mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "1tV0FUOQgnJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkxVB3cmG3lM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "np.random.seed = 20\n",
        "tf.random.set_seed(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Swlxr4b2P0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5177b2f1-4f6e-4b06-dca1-36ddfd7a828b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Jw26H4YoNn"
      },
      "source": [
        "Make the main repo as the current active repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkgfy2ZPMj5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8822b860-08b6-490b-dd86-48a503ced8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IR_repo\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/IR_repo')\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3vWKcjbY9R9"
      },
      "source": [
        "Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (56, 56, 3)\n",
        "names_list = os.listdir('dataset')\n",
        "num_categories = len(names_list)"
      ],
      "metadata": {
        "id": "C51FYTJiNkgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the name_to_label and label_to_name encodings"
      ],
      "metadata": {
        "id": "4nZkjl0fPCL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('name_to_label.json', 'r') as f:\n",
        "    name_to_label = json.load(f)\n",
        "with open('label_to_name.json', 'r') as f:\n",
        "    label_to_name = json.load(f)"
      ],
      "metadata": {
        "id": "N0S37j2xPDNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the features(X) and labels(y) from their respective numpy files"
      ],
      "metadata": {
        "id": "NRS1mudkPFuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('features.npy')\n",
        "y = np.load('labels.npy')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print('X_train:', X_train.shape)\n",
        "print('X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQrQMexPKFy",
        "outputId": "ce6b93b4-0278-426d-cae7-1639aa2a9d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (8800, 56, 56, 3)\n",
            "X_test: (2200, 56, 56, 3)\n",
            "y_train: (8800, 1)\n",
            "y_test: (2200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Data Augmentation"
      ],
      "metadata": {
        "id": "mJhF1icQPgqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip('horizontal'),\n",
        "        layers.RandomRotation(0.02),\n",
        "        layers.RandomWidth(0.2),\n",
        "        layers.RandomHeight(0.2)\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_augmentation.layers[0].adapt(X_train)"
      ],
      "metadata": {
        "id": "UMt-JY3iLtq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Supervised Contrastive Loss Function that will be used in training the model "
      ],
      "metadata": {
        "id": "xsxbj2dvRFXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # normalize the feature vectors\n",
        "        feature_vectors_normailzed = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute Logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normailzed, tf.transpose(feature_vectors_normailzed)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
      ],
      "metadata": {
        "id": "rR3Y2t3wS4pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an encoder to encode the images pixel data using the RNN - ResNet50V2"
      ],
      "metadata": {
        "id": "j0ES_vSeYNZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights=None, input_shape=input_shape, pooling='avg'\n",
        "    )\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name='encoder')\n",
        "    return model"
      ],
      "metadata": {
        "id": "vfqUfbAOXeOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a Projection head"
      ],
      "metadata": {
        "id": "XSpCGwfQdAEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_projection_head(encoder, projection_units):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation='relu')(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name='encoder_with_projection_head'\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "QkKIGzMEaehd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the encoder with Supervised Contrastive Loss defined above for better encoding"
      ],
      "metadata": {
        "id": "Hrr30sSHfMig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "projection_units = 256\n",
        "epochs = 50\n",
        "temperature = 0.05\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "encoder_with_projection_head = add_projection_head(encoder, projection_units)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature)\n",
        ")\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = encoder_with_projection_head.fit(\n",
        "        x=X_train, y=y_train, batch_size=batch_size, epochs=epochs\n",
        "    )"
      ],
      "metadata": {
        "id": "lEwNpfm5d2nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating and training the classifier using the pretrained encoder"
      ],
      "metadata": {
        "id": "hEU6SyBaBwj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classifier(encoder, dropout_rate, hidden_units, learning_rate, trainable=True):\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation='relu')(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_categories, activation='softmax')(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name = 'classifier')\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "FERzd63ofL12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.5\n",
        "hidden_units = 512\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "epochs = 100\n",
        "\n",
        "classifier = create_classifier(encoder, dropout_rate, hidden_units, learning_rate, trainable=False)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = classifier.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, stratify=y_train)\n",
        "\n",
        "accuracy = classifier.evaluate(X_test, y_test)[1]\n",
        "print(f'Test Accuracy: {round(accuracy*100,2)}%')"
      ],
      "metadata": {
        "id": "C_Mq2HYPN5uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('classifier.h5')"
      ],
      "metadata": {
        "id": "ciH3-UQO1tUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc+rwc6NFiiGCJdhr45GIO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}