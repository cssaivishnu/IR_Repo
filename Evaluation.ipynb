{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Upload that classifier model to the session storage before running"
      ],
      "metadata": {
        "id": "gGQIMI_1Skbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the github repo"
      ],
      "metadata": {
        "id": "fL3ZUnxt7gmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch main https://github.com/cssaivishnu/IR_Repo.git"
      ],
      "metadata": {
        "outputId": "24b07c87-d47f-423e-f78c-d7312e2a6b91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKesknPw7gmY"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IR_Repo'...\n",
            "remote: Enumerating objects: 63783, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 63783 (delta 49), reused 71 (delta 37), pack-reused 63687\u001b[K\n",
            "Receiving objects: 100% (63783/63783), 2.34 GiB | 23.38 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Updating files: 100% (76488/76488), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bx-ZiPa7gmY"
      },
      "source": [
        "Import the essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gkxVB3cmG3lM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "\n",
        "tf.random.set_seed(20)\n",
        "random.seed = 20\n",
        "np.random.seed = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOxYn1EL7gmZ"
      },
      "source": [
        "Make the main repo as the current active repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52fdd3a-38a3-49c9-af46-68f7c5000ec2",
        "id": "JxlHR-HN7gmZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IR_Repo\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/IR_Repo')\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3vWKcjbY9R9"
      },
      "source": [
        "From the complete dataset of approximately 63285 images from 35 categories, we consider only the product categories with atleast 150 images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func(name):\n",
        "    for i in range(len(name)):\n",
        "        if name[i] == '&' or name[i] == '-':\n",
        "            name = name[:i] + '_' + name[i+1:]\n",
        "    return name"
      ],
      "metadata": {
        "id": "8txyzYs7Yyj4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dBb7kdLvGf1"
      },
      "source": [
        "Create the label encodings mapping the product categories"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = 'dataset'\n",
        "i = 0\n",
        "name_to_label = dict()\n",
        "label_to_name = dict()\n",
        "name_list = sorted(os.listdir(dir_path))\n",
        "\n",
        "for name in name_list:\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        name = func(name)\n",
        "        name_to_label[name] = i\n",
        "        label_to_name[i] = name\n",
        "        i = i + 1"
      ],
      "metadata": {
        "id": "eDllHTjgUGMJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuBhqakg7gma"
      },
      "source": [
        "Load 500 out of 600 images from each product category and modify them to (56, 56) shape for training and evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OhANQRyX7gma"
      },
      "outputs": [],
      "source": [
        "dir_path = 'dataset'\n",
        "dataset = []\n",
        "image_shape = (56, 56)\n",
        "\n",
        "for name in name_list:\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        path = os.path.join(dir_path, name)\n",
        "        # print(name_to_label[name])\n",
        "        for f in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, f)):\n",
        "                num = int(f.split('.')[0])\n",
        "                if num > 500:\n",
        "                    continue\n",
        "                img_path = os.path.join(path, f)\n",
        "                img = Image.open(img_path)\n",
        "                img = img.resize(image_shape, Image.ANTIALIAS)\n",
        "                pixels = img.load()\n",
        "                lst = []\n",
        "                for i in range(img.size[0]):\n",
        "                    lst1 = []\n",
        "                    for j in range(img.size[1]):\n",
        "                        lst1.append(list(pixels[i, j]))\n",
        "                    lst.append(lst1)\n",
        "                lst = np.array(lst)\n",
        "                tupl = (lst,name_to_label[func(name)])\n",
        "                dataset.append(tupl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle the dataset for randomness and split the dataset into features(X) and labels(y)"
      ],
      "metadata": {
        "id": "WpLTWdp57gma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(dataset)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for tupl in dataset:\n",
        "    x, yy = tupl\n",
        "    X.append(x)\n",
        "    y.append(yy)\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(11000,1)\n",
        "\n",
        "# Just clear the space\n",
        "# dataset = []"
      ],
      "metadata": {
        "id": "uSMQef5d7gma"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ank6_wq74388"
      },
      "source": [
        "Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (56, 56, 3)\n",
        "num_categories = len(name_list)"
      ],
      "metadata": {
        "id": "C51FYTJiNkgt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into train and test data"
      ],
      "metadata": {
        "id": "NRS1mudkPFuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print('X_train:', X_train.shape)\n",
        "print('X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyQrQMexPKFy",
        "outputId": "e5b2370f-7ce7-4193-adeb-3cf1a5ebccb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (8800, 56, 56, 3)\n",
            "X_test: (2200, 56, 56, 3)\n",
            "y_train: (8800, 1)\n",
            "y_test: (2200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model uploaded to the session and get the prediction probabilities"
      ],
      "metadata": {
        "id": "-If0U58IBQeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = keras.models.load_model('classifier.h5')\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj6y32Wdntv-",
        "outputId": "d1d394b2-049f-4725-c98a-5405e6143319"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 11s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all the statistical metrics"
      ],
      "metadata": {
        "id": "Q1iYMnvkBOVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.reshape(2200)\n",
        "y_p = []\n",
        "for pred in y_pred:\n",
        "    y_p.append(np.argmax(pred))\n",
        "y_pred = np.array(y_p)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average=None)\n",
        "reca = recall_score(y_test, y_pred, average=None)\n",
        "f1_s = f1_score(y_test, y_pred, average=None)\n",
        "print(f'Test Accuracy: {round(ac*100,2)}%')"
      ],
      "metadata": {
        "id": "JNdW-IzopZt2",
        "outputId": "f962555f-8ed0-4b00-f878-1d9bb85c155a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 76.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create two Pandas DataFrames to note down the results and save them as a single excel file \n"
      ],
      "metadata": {
        "id": "8NVWyFLTBKIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [f'label_{i}' for i in range(22)]\n",
        "cm_df = pd.DataFrame(cm, columns=lst)\n",
        "cm_df.reset_index(inplace=True)\n",
        "cm_df.rename(columns={'index':'Product_Category'}, inplace=True)\n",
        "cm_df[\"Product_Category\"] = cm_df[\"Product_Category\"].apply(lambda x:label_to_name[x])\n",
        "cm_df.reset_index(inplace=True)\n",
        "cm_df.rename(columns={'index':'Labels'}, inplace=True)\n",
        "cm_df['Labels'] = cm_df['Labels'].apply(lambda x:f'label_{x}')"
      ],
      "metadata": {
        "id": "C4r_qhqUqFId"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = cm_df.iloc[:,1:2]\n",
        "metrics_df['Precision'] = prec\n",
        "metrics_df['Precision'] = metrics_df['Precision'].apply(lambda x: round(x, 3))\n",
        "metrics_df['Recall'] = reca\n",
        "metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: round(x, 3))\n",
        "metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: \"{:.3f}\".format(x)).astype(float)\n",
        "metrics_df['f1_score'] = f1_s\n",
        "metrics_df['f1_score'] = metrics_df['f1_score'].apply(lambda x: round(x, 3))\n",
        "mean = ['Average', metrics_df['Precision'].mean(), metrics_df['Recall'].mean(), metrics_df['f1_score'].mean()]\n",
        "min = ['Minimum', metrics_df['Precision'].min(), metrics_df['Recall'].min(), metrics_df['f1_score'].min()]\n",
        "max = ['Maximum', metrics_df['Precision'].max(), metrics_df['Recall'].max(), metrics_df['f1_score'].max()]\n",
        "metrics_df.loc[len(metrics_df)] = mean\n",
        "metrics_df.loc[len(metrics_df)] = min\n",
        "metrics_df.loc[len(metrics_df)] = max"
      ],
      "metadata": {
        "id": "txpsnDFZsLs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter('Results.xlsx')\n",
        "\n",
        "# Write each dataframe to a different sheet\n",
        "metrics_df.to_excel(writer, sheet_name='Metrics', index=False)\n",
        "cm_df.to_excel(writer, sheet_name='Confusion_Matrix', index=False)\n",
        "\n",
        "# Save the file\n",
        "writer.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9tiyjy01Nof",
        "outputId": "804e9d26-3510-4652-eb85-d134cf6e9af1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-ce1d72033f78>:8: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
            "  writer.save()\n"
          ]
        }
      ]
    }
  ]
}