{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cssaivishnu/IR_Repo/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload that classifier model to the drive in the My Drive folder itself to avoid changing path in the code before running"
      ],
      "metadata": {
        "id": "gGQIMI_1Skbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the github repo"
      ],
      "metadata": {
        "id": "fL3ZUnxt7gmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch main https://github.com/cssaivishnu/IR_Repo.git"
      ],
      "metadata": {
        "id": "eKesknPw7gmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bx-ZiPa7gmY"
      },
      "source": [
        "Import the essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gkxVB3cmG3lM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "\n",
        "tf.random.set_seed(20)\n",
        "random.seed = 20\n",
        "np.random.seed = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive to access the classifier model"
      ],
      "metadata": {
        "id": "hSHpJ23TAxTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "alhcxLONA3pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOxYn1EL7gmZ"
      },
      "source": [
        "Make the main repo as the current active repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxlHR-HN7gmZ"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/IR_Repo')\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func(name):\n",
        "    for i in range(len(name)):\n",
        "        if name[i] == '&' or name[i] == '-':\n",
        "            name = name[:i] + '_' + name[i+1:]\n",
        "    return name"
      ],
      "metadata": {
        "id": "8txyzYs7Yyj4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dBb7kdLvGf1"
      },
      "source": [
        "Create the label encodings mapping the product categories"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = 'dataset'\n",
        "i = 0\n",
        "name_to_label = dict()\n",
        "label_to_name = dict()\n",
        "name_list = sorted(os.listdir(dir_path))\n",
        "\n",
        "for name in name_list:\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        name = func(name)\n",
        "        name_to_label[name] = i\n",
        "        label_to_name[i] = name\n",
        "        i = i + 1"
      ],
      "metadata": {
        "id": "eDllHTjgUGMJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuBhqakg7gma"
      },
      "source": [
        "Load 500 out of 600 images from each product category and modify them to (56, 56) shape for training and evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OhANQRyX7gma"
      },
      "outputs": [],
      "source": [
        "dir_path = 'dataset'\n",
        "dataset = []\n",
        "image_shape = (56, 56)\n",
        "\n",
        "for name in name_list:\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        path = os.path.join(dir_path, name)\n",
        "        # print(name_to_label[name])\n",
        "        for f in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, f)):\n",
        "                num = int(f.split('.')[0])\n",
        "                if num > 500:\n",
        "                    continue\n",
        "                img_path = os.path.join(path, f)\n",
        "                img = Image.open(img_path)\n",
        "                img = img.resize(image_shape, Image.ANTIALIAS)\n",
        "                pixels = img.load()\n",
        "                lst = []\n",
        "                for i in range(img.size[0]):\n",
        "                    lst1 = []\n",
        "                    for j in range(img.size[1]):\n",
        "                        lst1.append(list(pixels[i, j]))\n",
        "                    lst.append(lst1)\n",
        "                lst = np.array(lst)\n",
        "                tupl = (lst,name_to_label[func(name)])\n",
        "                dataset.append(tupl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle the dataset for randomness and split the dataset into features(X) and labels(y)"
      ],
      "metadata": {
        "id": "WpLTWdp57gma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(dataset)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for tupl in dataset:\n",
        "    x, yy = tupl\n",
        "    X.append(x)\n",
        "    y.append(yy)\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(11000,1)\n",
        "\n",
        "# Just clear the space\n",
        "# dataset = []"
      ],
      "metadata": {
        "id": "uSMQef5d7gma"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ank6_wq74388"
      },
      "source": [
        "Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (56, 56, 3)\n",
        "num_categories = len(name_list)"
      ],
      "metadata": {
        "id": "C51FYTJiNkgt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into train and test data"
      ],
      "metadata": {
        "id": "NRS1mudkPFuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print('X_train:', X_train.shape)\n",
        "print('X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "metadata": {
        "id": "SyQrQMexPKFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model uploaded to the session and get the prediction probabilities"
      ],
      "metadata": {
        "id": "-If0U58IBQeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = keras.models.load_model('/content/drive/MyDrive/classifier.h5')\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "hj6y32Wdntv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all the statistical metrics"
      ],
      "metadata": {
        "id": "Q1iYMnvkBOVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.reshape(2200)\n",
        "y_p = []\n",
        "for pred in y_pred:\n",
        "    y_p.append(np.argmax(pred))\n",
        "y_pred = np.array(y_p)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average=None)\n",
        "reca = recall_score(y_test, y_pred, average=None)\n",
        "f1_s = f1_score(y_test, y_pred, average=None)\n",
        "print(f'Test Accuracy: {round(ac*100,2)}%')"
      ],
      "metadata": {
        "id": "JNdW-IzopZt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create two Pandas DataFrames to note down the results and save them as a single excel file \n"
      ],
      "metadata": {
        "id": "8NVWyFLTBKIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [f'label_{i}' for i in range(22)]\n",
        "cm_df = pd.DataFrame(cm, columns=lst)\n",
        "cm_df.reset_index(inplace=True)\n",
        "cm_df.rename(columns={'index':'Product_Category'}, inplace=True)\n",
        "cm_df[\"Product_Category\"] = cm_df[\"Product_Category\"].apply(lambda x:label_to_name[x])\n",
        "cm_df.reset_index(inplace=True)\n",
        "cm_df.rename(columns={'index':'Labels'}, inplace=True)\n",
        "cm_df['Labels'] = cm_df['Labels'].apply(lambda x:f'label_{x}')"
      ],
      "metadata": {
        "id": "C4r_qhqUqFId"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = cm_df.iloc[:,1:2]\n",
        "metrics_df['Precision'] = prec\n",
        "metrics_df['Precision'] = metrics_df['Precision'].apply(lambda x: round(x, 3))\n",
        "metrics_df['Recall'] = reca\n",
        "metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: round(x, 3))\n",
        "metrics_df['Recall'] = metrics_df['Recall'].apply(lambda x: \"{:.3f}\".format(x)).astype(float)\n",
        "metrics_df['f1_score'] = f1_s\n",
        "metrics_df['f1_score'] = metrics_df['f1_score'].apply(lambda x: round(x, 3))\n",
        "mean = ['Average', metrics_df['Precision'].mean(), metrics_df['Recall'].mean(), metrics_df['f1_score'].mean()]\n",
        "min = ['Minimum', metrics_df['Precision'].min(), metrics_df['Recall'].min(), metrics_df['f1_score'].min()]\n",
        "max = ['Maximum', metrics_df['Precision'].max(), metrics_df['Recall'].max(), metrics_df['f1_score'].max()]\n",
        "metrics_df.loc[len(metrics_df)] = mean\n",
        "metrics_df.loc[len(metrics_df)] = min\n",
        "metrics_df.loc[len(metrics_df)] = max"
      ],
      "metadata": {
        "id": "txpsnDFZsLs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter('Results.xlsx')\n",
        "\n",
        "# Write each dataframe to a different sheet\n",
        "metrics_df.to_excel(writer, sheet_name='Metrics', index=False)\n",
        "cm_df.to_excel(writer, sheet_name='Confusion_Matrix', index=False)\n",
        "\n",
        "# Save the file\n",
        "writer.save()"
      ],
      "metadata": {
        "id": "b9tiyjy01Nof"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}