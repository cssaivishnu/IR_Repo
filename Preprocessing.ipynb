{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cssaivishnu/IR_Repo/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9e4eRhtB52N"
      },
      "source": [
        "Import the essential libraries and mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkxVB3cmG3lM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import random\n",
        "\n",
        "random.seed = 20\n",
        "np.random.seed = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Swlxr4b2P0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d0cab3-b25f-4ccd-e22d-f175994b8441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Jw26H4YoNn"
      },
      "source": [
        "Make the main repo as the current active repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkgfy2ZPMj5C"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/IR_repo')\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3vWKcjbY9R9"
      },
      "source": [
        "From the complete dataset of approximately 63285 images from 35 categories, we consider only the product categories with atleast 150 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOoxFhBQN1w2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdb4f4d-1ec7-4450-faf8-a32654a9ae1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of categories: 35\n",
            "Number of categories with atleast 150 images: 22\n",
            "Number of categories with 600 images: 18\n",
            "Total Number of Images: 19196\n"
          ]
        }
      ],
      "source": [
        "dir_path = 'atlas_dataset_full'\n",
        "dir_count = 0\n",
        "active_dir_count = 0\n",
        "complete_dir_count = 0\n",
        "total_images = 0\n",
        "images_list = []\n",
        "\n",
        "for name in os.listdir(dir_path):\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        path = os.path.join(dir_path, name)\n",
        "        path = os.path.join(path, 'images')\n",
        "        num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "        if(num_files > 150):\n",
        "            active_dir_count = active_dir_count + 1\n",
        "            new_path = os.path.join('dataset', name)\n",
        "            os.mkdir(new_path)\n",
        "            i = 0\n",
        "            for f in os.listdir(path):\n",
        "                if i == 600:\n",
        "                    complete_dir_count = complete_dir_count + 1\n",
        "                    break\n",
        "                if os.path.isfile(os.path.join(path, f)):\n",
        "                    i = i + 1\n",
        "                    src = os.path.join(path, f)\n",
        "                    fname = '{:03d}'.format(i) + '.' + f.split('.')[-1]\n",
        "                    dst = os.path.join(new_path, fname)\n",
        "                    shutil.copy2(src, dst)\n",
        "            images_list.append(i)\n",
        "        total_images = total_images + i\n",
        "        dir_count += 1\n",
        "\n",
        "print(\"Total Number of categories:\", dir_count)\n",
        "print(\"Number of categories with atleast 150 images:\", active_dir_count)\n",
        "print(\"Number of categories with 600 images:\", complete_dir_count)\n",
        "print(\"Total Number of Images:\", total_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find that 22 out of these 35 categories only have atleast 150 images\n",
        "\n",
        "We want to have 600 images from each of the 22 product categories, out of which 4 of them have less than 600 images.\n",
        "\n",
        "Now, we will perform image augmentation to increase the number of images in those 4 product categories with less than 600 images to 600 images"
      ],
      "metadata": {
        "id": "p9-2Y9LG_df2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2b_YKONJFek"
      },
      "outputs": [],
      "source": [
        "# Here, the image is flipped horizontally to create a new image\n",
        "\n",
        "def horizontalflipping_augmentation(path, new_path):\n",
        "    # Define the horizontal flipping transformation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=1),\n",
        "    ])\n",
        "\n",
        "    # Load the image\n",
        "    img = Image.open(path)\n",
        "\n",
        "    # Apply the horizontal flipping transformation\n",
        "    img_flipped = transform(img)\n",
        "\n",
        "    # Display the original and flipped images\n",
        "    # img.show()\n",
        "    # img_flipped.show()\n",
        "\n",
        "    # Save the horizontally flipped image\n",
        "    img.save(new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bISEXc2PFUaY"
      },
      "outputs": [],
      "source": [
        "# Here, the image is modified by varying color glittering entities like contrast, brightness etc.\n",
        "\n",
        "def colorgittering_augmentation(path,new_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Define the range of color jittering values\n",
        "    brightness = 0.1\n",
        "    contrast = 0.1\n",
        "    saturation = 0.1\n",
        "    hue = 0.1\n",
        "\n",
        "    # Convert the image from BGR to HSV color space\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Apply color jittering to the image\n",
        "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * (1 + brightness), 0, 255)\n",
        "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * (1 + contrast), 0, 255)\n",
        "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * (1 + saturation), 0, 255)\n",
        "    img_hsv[:, :, 0] = np.clip(img_hsv[:, :, 0] * (1 + hue), 0, 255)\n",
        "\n",
        "    # Convert the image back to BGR color space\n",
        "    img_jittered = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # Display the original and jittered images\n",
        "    # cv2_imshow(img)\n",
        "    # cv2_imshow(img_jittered)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "    # Save the color gritted image\n",
        "    cv2.imwrite(new_path, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcdGedzTOWDM"
      },
      "outputs": [],
      "source": [
        "# Here, the image is randomly scaled to a feasible size\n",
        "\n",
        "def randomscaling_augmentation(path,new_path):\n",
        "    # Load the image\n",
        "    img = Image.open(path)\n",
        "    width, height = img.size\n",
        "    size = int(min(width,height)*0.9)\n",
        "\n",
        "    # Define the random scaling transformation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=size, scale=(0.8, 1.0)),\n",
        "    ])\n",
        "\n",
        "    # Apply the random scaling transformation\n",
        "    img_scaled = transform(img)\n",
        "\n",
        "    # Display the original and scaled images\n",
        "    # img.show()\n",
        "    # img_scaled.show()\n",
        "\n",
        "    # Save the randomly scaled image\n",
        "    img.save(new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EZYZlEw-zm3"
      },
      "outputs": [],
      "source": [
        "dir_path = 'dataset'\n",
        "images_list = []\n",
        "\n",
        "for name in os.listdir(dir_path):\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        path = os.path.join(dir_path, name)\n",
        "        num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "        images_list.append(num_files)\n",
        "        if num_files != 600:\n",
        "            # print(num_files)\n",
        "            # print(name)\n",
        "            for f in os.listdir(path):\n",
        "                if os.path.isfile(os.path.join(path, f)):\n",
        "                    img_name = int(f.split('.')[0])\n",
        "                    for i in range(1,4):\n",
        "                        new_img_name = img_name + num_files*i\n",
        "                        if new_img_name > 600:\n",
        "                            break\n",
        "                        new_img_name = '{:03d}'.format(new_img_name) + '.' + f.split('.')[-1]\n",
        "                        img_path = os.path.join(path,f)\n",
        "                        new_img_path = os.path.join(path,new_img_name)\n",
        "                        if i == 1:\n",
        "                            horizontalflipping_augmentation(img_path,new_img_path)\n",
        "                        if i == 2:\n",
        "                            colorgittering_augmentation(img_path,new_img_path)\n",
        "                        if i == 3:\n",
        "                            randomscaling_augmentation(img_path,new_img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dBb7kdLvGf1"
      },
      "source": [
        "Create the label encodings mapping the product categories and save them as JSON files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = 'dataset'\n",
        "i = 0\n",
        "name_to_label = dict()\n",
        "label_to_name = dict()\n",
        "\n",
        "for name in os.listdir(dir_path):\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        name_to_label[name] = i\n",
        "        label_to_name[i] = name\n",
        "        i = i + 1\n",
        "\n",
        "with open('name_to_label.json', 'w') as f:\n",
        "    json.dump(name_to_label, f)\n",
        "with open('label_to_name.json', 'w') as f:\n",
        "    json.dump(label_to_name, f)"
      ],
      "metadata": {
        "id": "eDllHTjgUGMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA_aLZBZwCRs"
      },
      "source": [
        "Load 500 out of 600 images from each product category and modify them to (56, 56) shape for training and evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdWasMiGBIoY"
      },
      "outputs": [],
      "source": [
        "dir_path = 'dataset'\n",
        "dataset = []\n",
        "names_list = os.listdir(dir_path)\n",
        "image_shape = (56, 56)\n",
        "\n",
        "for name in names_list:\n",
        "    if os.path.isdir(os.path.join(dir_path, name)):\n",
        "        path = os.path.join(dir_path, name)\n",
        "        # print(name_to_label[name])\n",
        "        for f in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, f)):\n",
        "                num = int(f.split('.')[0])\n",
        "                if num > 500:\n",
        "                    continue\n",
        "                img_path = os.path.join(path, f)\n",
        "                img = Image.open(img_path)\n",
        "                img = img.resize(image_shape, Image.ANTIALIAS)\n",
        "                pixels = img.load()\n",
        "                lst = []\n",
        "                for i in range(img.size[0]):\n",
        "                    lst1 = []\n",
        "                    for j in range(img.size[1]):\n",
        "                        lst1.append(list(pixels[i, j]))\n",
        "                    lst.append(lst1)\n",
        "                lst = np.array(lst)\n",
        "                tupl = (lst,name_to_label[name])\n",
        "                dataset.append(tupl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle the dataset for randomness and split the dataset into features(X) and labels(y)"
      ],
      "metadata": {
        "id": "RHqNOE3pIMTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(dataset)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for tupl in dataset:\n",
        "    x, yy = tupl\n",
        "    X.append(x)\n",
        "    y.append(yy)\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(11000,1)\n",
        "\n",
        "# Just clear the space\n",
        "dataset = []"
      ],
      "metadata": {
        "id": "ebBGsaQz4YBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the features(X) and labels(y) into numpy files so that we do not need to load the images again and again"
      ],
      "metadata": {
        "id": "1sfYATOU5CL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('features.npy', X)\n",
        "np.save('labels.npy', y)"
      ],
      "metadata": {
        "id": "8uE13yt_4iyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo0YEialHA38Dcv6qQF1YF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}